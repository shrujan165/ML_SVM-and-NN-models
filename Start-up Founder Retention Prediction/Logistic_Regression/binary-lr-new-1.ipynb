{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":120692,"databundleVersionId":14435901,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":41.898794,"end_time":"2025-11-17T19:50:17.536696","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-17T19:49:35.637902","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"10683011","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-27T14:37:45.333073Z","iopub.execute_input":"2025-11-27T14:37:45.333315Z","iopub.status.idle":"2025-11-27T14:37:47.911291Z","shell.execute_reply.started":"2025-11-27T14:37:45.333291Z","shell.execute_reply":"2025-11-27T14:37:47.910298Z"},"papermill":{"duration":1.703636,"end_time":"2025-11-17T19:49:41.501283","exception":false,"start_time":"2025-11-17T19:49:39.797647","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/start-up-founder-retention-prediction/sample_submission.csv\n/kaggle/input/start-up-founder-retention-prediction/train.csv\n/kaggle/input/start-up-founder-retention-prediction/test.csv\n","output_type":"stream"}],"execution_count":1},{"id":"200aacea","cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n\ntrain_df = pd.read_csv('/kaggle/input/start-up-founder-retention-prediction/train.csv') \ntest_df = pd.read_csv('/kaggle/input/start-up-founder-retention-prediction/test.csv') \n\n\nX_train = train_df.drop([\"retention_status\", \"founder_id\"], axis=1)\nX_test = test_df.drop(\"founder_id\", axis=1)\nfounder_ids = test_df[\"founder_id\"]\n\n\nle = LabelEncoder()\ny_train = le.fit_transform(train_df[\"retention_status\"])\n\n\nnumerical_cols = [\n    'founder_age', 'years_with_startup', 'monthly_revenue_generated', \n    'funding_rounds_led', 'distance_from_investor_hub', \n    'num_dependents', 'years_since_founding'\n]\n\n# Nominal  categorical features\nnominal_cols = [\n    'founder_gender', 'founder_role', 'working_overtime', \n    'education_background', 'personal_status', 'startup_stage', \n    'team_size_category', 'remote_operations', 'leadership_scope', \n    'innovation_support'\n]\n\n# Ordinal  categorical features \nordinal_cols = [\n    'work_life_balance_rating', 'venture_satisfaction', \n    'startup_performance_rating', 'startup_reputation', 'founder_visibility'\n]\n\n\nordinal_categories = [\n    ['Poor', 'Average', 'Good', 'Excellent'],  # work_life_balance_rating\n    ['Low', 'Medium', 'High'],                 # venture_satisfaction\n    ['Low', 'Average', 'High'],                 # startup_performance_rating\n    ['Poor', 'Fair', 'Good', 'Excellent'],    # startup_reputation\n    ['Low', 'Medium', 'High']                  # founder_visibility\n]\n\n\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n\nnominal_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n\nordinal_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n    ('ordinal', OrdinalEncoder(categories=ordinal_categories, handle_unknown='use_encoded_value', unknown_value=-1)) \n])\n\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_pipeline, numerical_cols),\n        ('nom', nominal_pipeline, nominal_cols),\n        ('ord', ordinal_pipeline, ordinal_cols)\n    ],\n    remainder='drop' \n)\n\n\n\n\nlogreg_pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression(random_state=42, max_iter=10000)) \n])\n\n\nparam_grid = {\n    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'classifier__penalty': ['l1', 'l2'],\n    'classifier__solver': ['liblinear'] \n}\n\n#Grid search done on parameter grid to find optimal ones\ngrid_search = GridSearchCV(\n    logreg_pipeline, \n    param_grid, \n    cv=5, \n    scoring='accuracy', \n    verbose=1, \n    n_jobs=-1 \n)\n\n\ngrid_search.fit(X_train, y_train)\n\n#Finding best CV accuracy and best hyperparameters using gridsearch\nprint(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\nprint(f\"Best hyperparameters: {grid_search.best_params_}\")\n\n\n\nbest_logreg = grid_search.best_estimator_\n\n\ny_pred_proba = best_logreg.predict_proba(X_test)[:, 1]\ny_pred_numeric = (y_pred_proba > 0.5).astype(int)\n\n\ny_pred = le.inverse_transform(y_pred_numeric)\n\n\nsubmission = pd.DataFrame({'founder_id': founder_ids, 'retention_status': y_pred})\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission file created.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-27T14:37:47.913209Z","iopub.execute_input":"2025-11-27T14:37:47.913675Z","iopub.status.idle":"2025-11-27T14:38:47.304622Z","shell.execute_reply.started":"2025-11-27T14:37:47.913648Z","shell.execute_reply":"2025-11-27T14:38:47.303666Z"},"papermill":{"duration":33.410842,"end_time":"2025-11-17T19:50:14.913902","exception":false,"start_time":"2025-11-17T19:49:41.503060","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 12 candidates, totalling 60 fits\nBest cross-validation accuracy: 0.7418\nBest hyperparameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\nSubmission file created.\n","output_type":"stream"}],"execution_count":2}]}
